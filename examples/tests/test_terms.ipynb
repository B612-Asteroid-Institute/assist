{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import ctypes\n",
    "import importlib\n",
    "\n",
    "#import ephem_forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mholman/assist/examples/tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.14844771e-16  4.10476669e-16  6.81638976e-16 -6.16164237e-16\n",
      " -5.61937486e-16  0.00000000e+00  0.00000000e+00  1.37233364e-16\n",
      "  1.73862338e-16  2.68004107e-16 -4.36254731e-16 -6.57978616e-16\n",
      "  0.00000000e+00 -1.76003844e-16 -3.98185133e-16]\n",
      "[ 1.55284966e-16 -2.97758132e-16 -5.35018122e-16  2.21442800e-16\n",
      "  1.93492843e-16 -3.91765774e-16  8.04021328e-16 -5.28234519e-16\n",
      " -2.60765994e-16  1.71581455e-16  0.00000000e+00 -6.13587810e-16\n",
      "  2.93203920e-16  1.81109411e-16 -3.49506207e-16]\n",
      "[ 1.87992928e-16  6.43421342e-15  6.47637863e-15 -6.43255908e-15\n",
      " -6.34586763e-15 -1.91748009e-16  1.58487783e-16  5.15500774e-16\n",
      "  7.76347656e-16  2.02659288e-16  5.67733013e-16 -2.73920308e-16\n",
      "  1.94077516e-16  5.43691898e-16 -5.24641862e-16]\n",
      "[ 2.57797929e-16  1.63276287e-16  2.02368098e-16 -3.91541660e-16\n",
      " -1.98956969e-16 -8.07638626e-16 -1.02633541e-15 -1.00025965e-15\n",
      " -8.23345095e-16 -1.08046300e-15  4.74463652e-16  6.83262060e-16\n",
      " -8.91173496e-16  3.91340965e-16  5.63559364e-16]\n",
      "[ 1.99819038e-16  1.17597427e-15  1.09873516e-15  2.00812188e-15\n",
      " -1.48954791e-15 -1.86470102e-16  5.12217802e-16 -1.66442941e-16\n",
      "  3.75380482e-16 -2.26589597e-16  0.00000000e+00 -2.20228586e-16\n",
      " -1.39393938e-16  1.12483329e-16 -5.41923022e-16]\n",
      "[ 5.11344522e-16  2.79752384e-16  8.27227118e-16  4.83974872e-16\n",
      "  7.50136496e-16 -7.72400413e-16 -4.36040276e-16 -1.55600887e-16\n",
      "  0.00000000e+00 -8.24184545e-16  6.21648399e-16  4.80435486e-16\n",
      " -5.83949225e-16  3.42571295e-16  3.97129809e-16]\n",
      "[-1.18704309e-16  2.87631828e-16  3.66909220e-16 -1.17022210e-16\n",
      "  0.00000000e+00  1.27825902e-16  1.13022545e-15 -4.18302191e-16\n",
      " -1.63742923e-16  3.14462824e-16  0.00000000e+00  3.24932033e-16\n",
      "  0.00000000e+00  1.69102893e-16  5.86843280e-16]\n",
      "[-1.88270518e-15  6.57035713e-16 -1.15326959e-15 -1.48538048e-15\n",
      " -1.52254401e-15  4.24362733e-16 -2.62794107e-16 -2.79992600e-16\n",
      "  0.00000000e+00 -2.52967028e-16 -7.80868184e-16 -4.69107331e-16\n",
      "  0.00000000e+00 -5.29515141e-16  0.00000000e+00]\n",
      "[ 1.27362259e-14  1.48083767e-16 -6.05586775e-16  9.73064789e-16\n",
      "  1.16518077e-15  4.72451682e-16 -3.53617549e-16 -4.34358809e-16\n",
      " -2.79015720e-16 -7.56245757e-16  9.83972310e-16  1.46076583e-15\n",
      " -4.91484821e-16  8.52646025e-16  1.18669134e-15]\n",
      "[ 1.34907015e-15  3.50930771e-16 -2.39509348e-16  6.66425667e-16\n",
      "  1.87059820e-16  1.21490131e-16 -1.46519311e-16  1.16468722e-16\n",
      "  2.16125860e-16  6.39568237e-16 -2.31962223e-16 -6.46263784e-16\n",
      "  5.38448167e-16 -1.22054640e-16 -5.44085103e-16]\n",
      "[ 0.00000000e+00  3.67056384e-14  3.65582983e-14 -3.69006142e-14\n",
      " -3.67224281e-14 -1.99560871e-16  0.00000000e+00 -2.19668790e-16\n",
      "  2.70701789e-16  3.33134438e-14 -1.96774857e-15 -5.27433323e-15\n",
      "  3.31264192e-14 -2.13076385e-15 -5.48282663e-15]\n"
     ]
    }
   ],
   "source": [
    "line_switch={0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:10, 9:11, 10:12, 11:13, 12:14, 13:15,\n",
    "            14:16, 15:17, 16:18, 17:19, 18:20, 19:21, 20:8, 21:9}\n",
    "\n",
    "with open('jpl.out') as file:\n",
    "    jpl_lines = file.readlines()\n",
    "\n",
    "\n",
    "with open('eih_acc.out') as file:\n",
    "    rebx_lines = file.readlines()\n",
    "    \n",
    "\n",
    "for i, line in enumerate(jpl_lines):\n",
    "    jpl_line=line.strip()\n",
    "    rebx_line = rebx_lines[line_switch[i]].strip()\n",
    "    if jpl_line.startswith('EIH_J'):\n",
    "        continue\n",
    "    else:\n",
    "        jpl_line = np.array(jpl_line.split(), dtype=np.double)\n",
    "        rebx_line = np.array(rebx_line.split(), dtype=np.double)\n",
    "        print((rebx_line-jpl_line)/np.abs(jpl_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "\n",
      "[ 0.00000000e+00 -1.30384018e-16  0.00000000e+00 -1.88616970e-16\n",
      "  0.00000000e+00  0.00000000e+00  1.44291750e-16]\n",
      "\n",
      "[ 0.00000000e+00 -1.69533710e-16  0.00000000e+00  0.00000000e+00\n",
      "  1.56449808e-16  0.00000000e+00  0.00000000e+00]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00 -2.44861357e-16  0.00000000e+00\n",
      "  0.00000000e+00  2.66234966e-16  0.00000000e+00]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00 -2.44930438e-16 -1.24489176e-16\n",
      "  0.00000000e+00  3.37649866e-16  1.71615068e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  3.13324702e-15 -3.32017520e-16\n",
      "  0.00000000e+00 -3.15973913e-15  3.21431791e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00 -3.45927855e-16  0.00000000e+00\n",
      " -7.87902428e-16 -3.84139744e-16 -7.14476537e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  1.16845539e-16  2.79453211e-16\n",
      " -3.77659702e-16  3.61352922e-16  2.16057103e-16]\n",
      "\n",
      "[0.00000000e+00 4.13657059e-16 0.00000000e+00 1.82036384e-16\n",
      " 4.45424433e-16 8.78470155e-16 7.35060463e-16]\n",
      "\n",
      "[ 0.00000000e+00  2.74339357e-16  0.00000000e+00  1.75947779e-16\n",
      "  6.05365818e-16 -8.33751216e-16 -9.70629701e-16]\n",
      "\n",
      "[ 0.00000000e+00  1.84383249e-16  1.28259847e-16 -2.88011283e-16\n",
      " -3.03089743e-16  0.00000000e+00  4.73433820e-16]\n",
      "\n",
      "[ 1.22526684e-16  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -3.84329481e-16  4.20041086e-16  4.21012269e-16]\n",
      "\n",
      "[ 0.00000000e+00 -1.90182738e-16  3.03009310e-16 -2.69052054e-16\n",
      " -3.45937704e-16 -9.18610755e-16 -3.26266029e-16]\n",
      "\n",
      "[ 1.88567737e-16  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.60992284e-16  1.89102603e-16  2.31332490e-16]\n",
      "\n",
      "[ 1.81689300e-16  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.23289197e-16  1.51561911e-16  1.57265525e-16]\n",
      "\n",
      "[-1.74883484e-16 -3.72749840e-16  0.00000000e+00  1.19588913e-16\n",
      "  0.00000000e+00  2.68519604e-16  2.43456910e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  5.78059905e-16  0.00000000e+00\n",
      "  0.00000000e+00 -6.16950128e-16  0.00000000e+00]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[ 0.00000000e+00 -4.27821234e-16  0.00000000e+00  0.00000000e+00\n",
      "  6.17843381e-16 -1.11147162e-16 -2.22932634e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00 -1.18162248e-16  0.00000000e+00\n",
      "  0.00000000e+00  3.38484518e-16 -1.46104574e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  3.17819159e-16  0.00000000e+00\n",
      " -2.47041979e-16 -4.13977340e-16 -1.22613909e-16]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.73339560e-16\n",
      "  0.00000000e+00  0.00000000e+00 -1.40851768e-16]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[ 0.00000000e+00  0.00000000e+00  2.19238563e-16  4.03044263e-16\n",
      "  0.00000000e+00 -2.18709387e-16 -4.02071436e-16]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[ 0.00000000e+00 -1.81241932e-16  0.00000000e+00  0.00000000e+00\n",
      "  1.79614542e-16  0.00000000e+00  0.00000000e+00]\n",
      "\n",
      "[ 0.00000000e+00 -2.11564831e-16  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.95982155e-16  3.80250226e-16]\n",
      "\n",
      "J2 [-1.01222644e-13  1.01586529e-13  2.93884317e-13]\n",
      "solar J2 [-1.18300707e-16 -3.29679439e-16  5.27415829e-16]\n",
      "GR [ 6.17064942e-16 -6.36303130e-16 -3.36165494e-16]\n",
      "GR [ 9.86144296e-16 -1.01892890e-15 -6.72541352e-16]\n"
     ]
    }
   ],
   "source": [
    "with open('force_genrel.dat') as file:\n",
    "    genrel_lines = file.readlines()\n",
    "    \n",
    "with open('force_eihrel.dat') as file:\n",
    "    eih_lines = file.readlines()\n",
    "    \n",
    "with open('force_eihrel_sun_only.dat') as file:\n",
    "    eih_sun_only_lines = file.readlines()   \n",
    "\n",
    "# Verify that the first set of lines in the three files\n",
    "# from Davide are the same\n",
    "for i, line in enumerate(genrel_lines):\n",
    "    if i>26:\n",
    "        break\n",
    "    if line != eih_lines[i]:\n",
    "        print('foo')\n",
    "    if line != eih_sun_only_lines[i]:\n",
    "        print('bar')\n",
    "\n",
    "with open('acc.out') as file:\n",
    "    assist_lines = file.readlines()\n",
    "    \n",
    "line_switch={0:0, 1:1, 2:2, 3:3, 4:10, 5:4, 6:5, 7:6, 8:7, 9:8, 10:9, 11:22, 12:11, 13:26,\n",
    "            14:15, 15:19, 16:25, 17:17, 18:14, 19:16, 20:24, 21:20, 22:13, 23:21, 24:18, \n",
    "            25:23, 26:12}\n",
    "\n",
    "# Check relative position vectors and acceleration terms\n",
    "for i, line in enumerate(assist_lines):\n",
    "    if i>26:\n",
    "        break\n",
    "    assist_line=np.array(line.strip().split(), dtype=np.double)\n",
    "    jpl_line = np.array(genrel_lines[line_switch[i]].strip().split(), dtype=np.double)\n",
    "    if i==0:\n",
    "        #print(assist_line[3:])\n",
    "        #print(jpl_line[2:])\n",
    "        print((assist_line[3:6]-jpl_line[2:5])/np.abs(jpl_line[2:5]))\n",
    "    else:\n",
    "        print((assist_line[2:9]-jpl_line[2:9])/np.abs(jpl_line[2:9]))\n",
    "    print()\n",
    "    \n",
    "    #print((rebx_line-jpl_line)/np.abs(jpl_line))\n",
    "\n",
    "assist_J2 = np.array(assist_lines[27].strip().split()[2:], dtype=np.double)\n",
    "genrel_J2 = np.array(genrel_lines[27].strip().split()[2:], dtype=np.double)\n",
    "\n",
    "print('J2', (assist_J2-genrel_J2)/np.abs(genrel_J2))\n",
    "\n",
    "assist_sJ2 = np.array(assist_lines[28].strip().split()[2:], dtype=np.double)\n",
    "genrel_sJ2 = np.array(eih_sun_only_lines[28].strip().split()[2:], dtype=np.double)\n",
    "\n",
    "print('solar J2', (assist_sJ2-genrel_sJ2)/np.abs(genrel_sJ2))\n",
    "\n",
    "assist_GR = np.array(assist_lines[29].strip().split()[2:], dtype=np.double)\n",
    "genrel_GR = np.array(genrel_lines[29].strip().split()[2:], dtype=np.double)\n",
    "\n",
    "print('GR', (assist_GR-genrel_GR)/np.abs(genrel_GR))\n",
    "\n",
    "assist_EIH = np.array(assist_lines[30].strip().split()[2:], dtype=np.double)\n",
    "force_eih_GR = np.array(eih_lines[29].strip().split()[2:], dtype=np.double)\n",
    "\n",
    "print('GR', (assist_EIH-force_eih_GR)/np.abs(force_eih_GR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.92869791e-08 -8.10684267e-08  1.77015156e-08]\n",
      "[ 8.95155743e-07 -9.30518946e-09  3.47471726e-07]\n",
      "[ 6.31206830e-07 -3.98885280e-07  3.51410357e-10]\n",
      "[-4.38362556e-07  5.64081904e-07  5.74208883e-07]\n",
      "[ 3.13335876e-06 -5.66743705e-08 -3.11300774e-06]\n",
      "[ 2.41923972e-06 -2.45160133e-06 -7.30224636e-08]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.direct') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.38650288e-08 -2.60225866e-08  2.87365654e-08]\n",
      "[ 1.12030028e-06  2.18476151e-09 -9.64480694e-07]\n",
      "[-5.87934382e-07 -5.06544617e-07 -2.07347072e-09]\n",
      "[-5.46341572e-07 -6.55911870e-07  6.56058648e-07]\n",
      "[ 3.31100201e-06  5.40837401e-08 -3.30700314e-06]\n",
      "[ 7.07800961e-06  7.07898687e-06 -4.22686253e-08]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.earth_J2J4') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.19973801e-08  1.12910976e-07 -1.51223539e-07]\n",
      "[-9.49812156e-08  3.73452505e-09 -3.68843833e-08]\n",
      "[-2.09689990e-08 -2.15908040e-08 -5.87505966e-09]\n",
      "[-6.87206451e-07  7.11064260e-07 -4.30341134e-07]\n",
      "[ 1.73724395e-06 -2.19812124e-07  1.44267175e-07]\n",
      "[ 5.87099855e-06 -1.01194792e-07  9.21653189e-09]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.solar_J2') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.50951836e-08 -2.25445490e-09  8.65487477e-08]\n",
      "[ 2.08024014e-08  2.02632176e-08 -2.33727639e-08]\n",
      "[-6.08141348e-07  1.49546632e-06  6.52428175e-09]\n",
      "[ 4.09563710e-07 -4.54683712e-07 -6.28431458e-07]\n",
      "[-1.62645415e-06  7.13028372e-08 -1.11332370e-06]\n",
      "[-2.77055923e-06  1.85752209e-06  2.29298505e-07]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.non_gravs') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.18729250e-09 -6.59437455e-08 -2.18111615e-07]\n",
      "[1.05834821e-07 1.45107275e-08 4.86997877e-09]\n",
      "[-1.07096277e-07 -1.05465937e-08 -4.31593155e-09]\n",
      "[ 3.90974626e-06 -5.64084170e-07 -5.51433805e-07]\n",
      "[-9.95232342e-07  5.23365818e-07  1.38063088e-06]\n",
      "[-2.97511256e-06  6.50218437e-06  2.42543839e-07]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.simple_GR') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.69563621e-08  1.71652071e-08 -1.42077139e-07]\n",
      "[ 4.13620157e-07  1.77524410e-09 -7.04727909e-09]\n",
      "[5.84200044e-07 4.22751772e-08 4.79186144e-09]\n",
      "[ 3.89744668e-06 -5.64010726e-07 -5.51366339e-07]\n",
      "[-9.93379646e-07  5.23336435e-07  1.38078598e-06]\n",
      "[-2.96869409e-06  6.50852122e-06  2.42547514e-07]\n"
     ]
    }
   ],
   "source": [
    "with open('vary_acc.out.eih_solar_only') as file:\n",
    "    var_lines = file.readlines()\n",
    "    for i in range(6):\n",
    "        difference_line=np.array(var_lines[i].strip().split()[2:], dtype=np.double)\n",
    "        var_line=np.array(var_lines[i+6].strip().split()[2:], dtype=np.double)\n",
    "        print((difference_line-var_line)/np.abs(var_line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate the ASSIST ephemeris-quality integrator by calling a python-wrapped C function that has been compiled into a library.  That library is imported with the ephem_forces.py package.\n",
    "\n",
    "The primary function in ephem_forces is 'integration_function', although we will access it with a higher-level function called 'production_integration_function_wrapper'.  \n",
    "\n",
    "'integration_function' integrates massless test particles in the field of the Sun, planets, moon, and 16 massive asteroids.  It also includes the J2 and J4 gravitational harmonics of the Earth, the J2 gravitational harmonic of the Sun, and the solar GR terms (using the PPN formulation).  \n",
    "\n",
    "The positions of the massive bodies come from two binary files, both from JPL.  The first is for the Sun, planets, and moon, with the latest DE441 ephemeris. The other is for the asteroids, corresponding to DE441.  \n",
    "\n",
    "The coordinate frame and units are not flexible, currently.  The coordinate frame is the equatorial ICRF, which is the native coordinate system for the JPL binary files.  Note that this is equatorial rather than ecliptic.  In addition, the native coordinates are barycentric, rather than heliocentric. \n",
    "\n",
    "For units we use solar masses, au, and days.  The independent time coordinate is TDB in Julian days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the one being compared to Davide's stuff.\n",
    "# DE441 \n",
    "# heliocentric\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.342674681639715E+00 Y =-9.244683523355280E-01 Z =-5.068395961023143E-01\n",
    "# VX= 2.814015548668069E-03 VY= 7.552327120972679E-03 VZ= 2.980608879703206E-03\n",
    "row = [3.342674681639715E+00, -9.244683523355280E-01, -5.068395961023143E-01,\n",
    "    2.814015548668069E-03, 7.552327120972679E-03, 2.980608879703206E-03]\n",
    "instates = np.array([row])\n",
    "GMsun, sun = ephem_forces.all_ephem(0, 2458849.500000000)\n",
    "res = instates[0] + sun[0:6]\n",
    "row = []\n",
    "for j in range(6):\n",
    "    row.append(res[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in row:\n",
    "    print('%.16le' %(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "# (3666) Holman\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.338875350265349E+00 Y =-9.176518267602161E-01 Z =-5.038590677470149E-01\n",
    "# VX= 2.805663315227095E-03 VY= 7.550408688437705E-03 VZ= 2.980028207454247E-03\n",
    "    \n",
    "#row =[3.338875350265349E+00, -9.176518267602161E-01, -5.038590677470149E-01, 2.805663315227095E-03, 7.550408688437705E-03, 2.980028207454247E-03]\n",
    "row = [3.338875349745594E+00, -9.176518281675284E-01, -5.038590682977396E-01, 2.805663319000732E-03, 7.550408687780768E-03, 2.980028206579994E-03]\n",
    "\n",
    "instates = np.array([row])\n",
    "n_particles = 1\n",
    "\n",
    "#tstart, tstep, trange = 2458849.5, 20.0, 100\n",
    "\n",
    "epoch, tstart, tstep, trange = 2458849.5, 2458849.5, 20.0, 1\n",
    "#epoch = tstart\n",
    "\n",
    "tend = tstart + trange\n",
    "\n",
    "print(tstart, tend, tstep)\n",
    "\n",
    "times, states, var, var_ng, status = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates)\n",
    "\n",
    "\n",
    "times, states#, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0], states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instates2 = states[-1]\n",
    "tstart2 = times[-1]\n",
    "tend2 = tstart\n",
    "tstep2 = -tstep\n",
    "epoch2 = tstart2\n",
    "\n",
    "times2, states2, var2, var_ng2, status2 = ephem_forces.production_integration_function_wrapper(tstart2, tend2, epoch2, instates2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0]-states2[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "The integrator works.  Now it's time to use it.  \n",
    "\n",
    "1. Integrate over some interval, outputting substeps for each integration step.\n",
    "2. Use the output of the substeps to generate Chebyshev polynomials for each integration step.\n",
    "3. Use those to accurately interpolate the position, and possiby velocity, of the integrated object at any time within the interval.\n",
    "\n",
    "4. Get the observatory position at a set of UTC times.\n",
    "5. Use iterative light-time correction to get the observed position of the object at those times.\n",
    "\n",
    "6. Integrate initial conditions to match a set of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect some initial conditions from JPL Horizons.  For asteroid (3666) Holman, we grab the barycentric position and velocity vectors, in units of au and au/day."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DE441 \n",
    "# heliocentric\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.342674681639715E+00 Y =-9.244683523355280E-01 Z =-5.068395961023143E-01\n",
    "# VX= 2.814015548668069E-03 VY= 7.552327120972679E-03 VZ= 2.980608879703206E-03\n",
    "row = [3.342674681639715E+00, -9.244683523355280E-01, -5.068395961023143E-01,\n",
    "    2.814015548668069E-03, 7.552327120972679E-03, 2.980608879703206E-03]\n",
    "instates = np.array([row])\n",
    "GMsun, sun = ephem_forces.all_ephem(0, 2458849.500000000)\n",
    "res = instates[0] + sun[0:6]\n",
    "row = []\n",
    "for j in range(6):\n",
    "    row.append(res[j])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DE441\n",
    "# (394130)\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X =-3.695208756154107E+00 Y =-1.527448283346847E+00 Z = 3.831835238155900E-01\n",
    "# VX=-4.777297716907912E-03 VY=-3.105101882755925E-03 VZ=-8.479422803126437E-04\n",
    "row = [-3.695208756154107E+00, -1.527448283346847E+00, 3.831835238155900E-01, -4.777297716907912E-03, -3.105101882755925E-03, -8.479422803126437E-04]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "production_integration_function_wrapper is called with\n",
    "\n",
    "tstart: the start time of the output, in JD (TDB).\n",
    "\n",
    "tend: the end time of the output, in JD (TDB).\n",
    "    \n",
    "tepoch: the time at which the initial conditions, in JD (TDB).  Note that tepoch does not need to correspond to tstart or tend, nor does it need to be within the range of tstart and tend.\n",
    "\n",
    "instates: an array of 6-vectors, each of which is the position and velocity of a test particle at tstart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is:\n",
    "\n",
    "times: a numpy array of the times of output\n",
    "\n",
    "states: a numpy array of 6-vectors, one for each real particle at each output time.\n",
    "\n",
    "var: a numpy array of 6-vectors, one for each variational particle at each output time.\n",
    "\n",
    "var_ng: a numpy array of vectors (length?) to represent the variations with respect to the non-gravitational parameters.\n",
    "\n",
    "status: a flag indicating the outcome of the integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we integrate this one particle for 10,000 days.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ICRF = np.array([[3.342674681643655E+00, -9.244683523067124E-01, -5.068395960908961E-01],\n",
    "[-6.333487647947349E-02, -4.101490687134884E-01, -2.125333556435262E-01],\n",
    "[7.232003000354648E-01,  6.452613453400362E-02, -1.672592916740240E-02]]).T\n",
    "\n",
    "\n",
    "Sun = np.array([[2.954252700212495E+00, -1.854271523442791E+00,  3.450655568440782E-01],\n",
    "[-1.747882863116961E-01, -4.315392487974600E-01, -2.503845286462576E-02],\n",
    "[ 7.126571683328389E-01, -1.320988590792954E-01,  4.617038628350368E-02]]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =np.matmul(Sun, np.linalg.inv(ICRF))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(A, ICRF).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sun2 = np.array([ [4.801408493039603E-03,  7.124341862325499E-03, -1.748921268090565E-04],\n",
    "[2.098843615617622E-02, -7.999979434585941E-03,  5.768534258146244E-04],\n",
    "[3.591911441598157E-03,  1.981620334762863E-02, -4.506803543425547E-04]]).T\n",
    "\n",
    "    \n",
    "ICRF2 = np.array([[2.814015548590179E-03,  7.552327121010698E-03, 2.980608879721585E-03],\n",
    " [2.222816776857887E-02, -1.312708321506106E-03, -3.005368134707854E-03],\n",
    "[-1.547265544170301E-03,  1.827913575812348E-02, 8.322621039826183E-03]]).T\n",
    "\n",
    "A2 =np.matmul(Sun2, np.linalg.inv(ICRF2))\n",
    "A2, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICRF3=np.array([\n",
    "[ 5.261470562231202E-01,-4.775755205715124E+00,-2.059828630438416E+00],\n",
    "[ 3.797244866040094E+00,-8.525772233967986E+00,-3.685112112121498E+00],\n",
    "[ 1.622549719742635E+01, 1.050684419907994E+01, 4.372286327065908E+00]]).T\n",
    "    \n",
    "Sun3=np.array([\n",
    "[-8.213545652596842E-01,-5.157271791096192E+00, 2.355564631924294E-01],\n",
    "[ 1.279151598704325E+00,-9.923169928963429E+00, 7.631394273132386E-01],\n",
    "[ 1.850574842701914E+01, 6.940241275563274E+00, 1.465519787012176E+00]]).T\n",
    "\n",
    "A3 =np.matmul(Sun3, np.linalg.inv(ICRF3))\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAp = np.arcsin(-9.60633821e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.sin(RAp), -np.sin(Decs)*np.cos(RAp), np.cos(Decs)*np.cos(RAp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cos(RAp),   -np.sin(Decs)*np.sin(RAp), np.cos(Decs)*np.sin(RAp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0., np.cos(Decs), np.sin(Decs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl = np.array([-1.3023962309511364E-17, 4.6734608690892943E-18, -5.4774520501613936E-19])\n",
    "ours =np.array([-3.7943075433312321e-18, -1.3395935992098073e-17, 1.1491334453974039e-18])\n",
    "ours2 = np.array([-1.3294155428915666e-17, 3.3360189304865425e-18, 2.7027370646008695e-18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin = np.array([3.3426746816397150e+00, -9.2446835233552804e-01, -5.0683959610231433e-01])\n",
    "vout = np.array([9.5483022397623252e-01, 3.3710616278817742e+00, -9.6150311111680320e-02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(vin), np.linalg.norm(vout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 2.954252700212495E+00 Y =-1.854271523442791E+00 Z = 3.450655568440782E-01\n",
    "# VX= 4.801408493039603E-03 VY= 7.124341862325499E-03 VZ=-1.748921268090565E-04\n",
    "# This is the sun-asteroid vector in the frame of the Sun's equator at this epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(jpl), np.linalg.norm(ours), np.linalg.norm(ours2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAs = 268.13*np.pi/180.\n",
    "Decs = 63.87*np.pi/180.\n",
    "\n",
    "xz = np.cos(Decs)*np.cos(RAs)\n",
    "yz = np.cos(Decs)*np.sin(RAs)\n",
    "zz = np.sin(Decs)\n",
    "\n",
    "incl = np.arccos(zz)\n",
    "longnode = np.arctan2(xz, -yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz, yz, zz, incl*180/np.pi, longnode*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = -yz\n",
    "yy =  xz\n",
    "zy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we swap the start and end points, we get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tend, tstart, epoch, instates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(statesp-states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we keep the same epoch but cut down the range, the overlapping section is nearly the same, to the few meter level.  Numerically, this probably due to slightly different step sizes being used.  It might be the best that can be achieved with the precision of the positions of the  planets and asteroids.  Regardless, it is extremely small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tend-2000, tend, epoch, instates)#, epsilon=1e-8, tstep=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(statesp[-1][0]-states[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying numerical integrator is IAS15 (Rein & Liu 2015), a 15th order predictor-corrector integrator with an adaptive step-size.  Each time step involves eight sub-steps.  We have modified the integrator to output the state at each of the sub-steps in order to support interpolation of the output.\n",
    "\n",
    "Below is a plot of the overall step-size as a function of elapsed integration time.  (The sub-steps are smaller).  A rough periodicity on the ~2000 day asteroid orbital period is evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=(times-times[0])[::8]\n",
    "dt=t[1:]-t[:-1]\n",
    "\n",
    "plt.plot(t[:-1], dt)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"step-size (days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a histogram of the step-sizes.  Most are 15-25 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(dt,bins=30)\n",
    "plt.xlabel(\"step-size (days)\")\n",
    "plt.ylabel(\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the xyz values as a function of time.  The coordinate system is equatorial, so the z component is not nearly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.plot(times-times[0], states[:,0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states[:,0,0], states[:,0,1], linewidth=0.2)\n",
    "plt.axis('square')\n",
    "plt.xlabel('x (AU)')\n",
    "plt.ylabel('y (AU)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compare the output to what JPL Horizons gives.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No non-gravs\n",
    "# dt_min = 1e-2\n",
    "# epsilon = 1e-8\n",
    "\n",
    "# This is from JPL Horizons, using DE441 for the planets and sb441-n16 for the massive asteroids.\n",
    "\n",
    "#2468849.500000000 = A.D. 2047-May-19 00:00:00.0000 TDB [del_T=     69.185214 s]\n",
    "# X = 3.170610684726161E+00 Y =-1.304064355874703E+00 Z =-6.557860840042533E-01\n",
    "# VX= 3.883515127959035E-03 VY= 7.175467895958359E-03 VZ= 2.785507467676363E-03\n",
    "\n",
    "#DE441\n",
    "\n",
    "holman = np.array([3.170610684726161E+00, -1.304064355874703E+00, -6.557860840042533E-01,\n",
    "                   3.883515127959035E-03, 7.175467895958359E-03, 2.785507467676363E-03])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No non-gravs\n",
    "# dt_min = 1e-2\n",
    "# epsilon = 1e-8\n",
    "\n",
    "# This is from JPL Horizons, using DE441 for the planets and sb441-n16 for the massive asteroids.\n",
    "\n",
    "#(394130)\n",
    "#2468849.500000000 = A.D. 2047-May-19 00:00:00.0000 TDB [del_T=     69.185214 s]\n",
    "# X =-3.504730383385668E+00 Y =-2.123262871413949E+00 Z =-5.234096631335790E-01\n",
    "# VX= 5.050680077417927E-03 VY= 1.883409101375705E-03 VZ=-8.444052595199177E-04\n",
    "\n",
    "ast_394130 = np.array([-3.504730383385668E+00, -2.123262871413949E+00, -5.234096631335790E-01, 5.050680077417927E-03, 1.883409101375705E-03, -8.444052595199177E-04])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agreement after ~27 years is excellent, ~25 m or 1e-2 mas (assuming the object is 3 AU away)!  The remaining difference is probably due to the integrator or differences in the precision of the constants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((states[-1][0]-holman)/3)*206265, (states[-1][0]-holman)*1.5e11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((states[-1][0]-ast_394130)/3)*206265, (states[-1][0]-ast_394130)*1.5e11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output states in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.shape, states.shape, n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about 'var' in the output?  It looks like there are extra particles.  In fact, for each actual particle production_integration_function_wrapper generates six \"variational particles\" or tangent vectors.  These are vectors with the same dimensionality as an actual particle state, but they are the result of integrating the linearized tangent equations, or variational equations.  There is one variational particle for each of the six dimensions, with the initial state being a unit vector.\n",
    "\n",
    "One way to think of the variational equations is to consider two states that are initially close to each other.  As we integrate both the two states will begin to separate.  We can imagine a vector pointing from one of the particles to the other.  (This is a vector is all six dimensions, both positions and velocities.) \n",
    "\n",
    "Suppose that instead of integrating the two particles we could integrate one of the particles and the vector from that particle to the other.  In addition to the equations of motion for the actual particle, we would need the equations of motion for the state vector between the two.  \n",
    "\n",
    "That is what the linearized variational equations are, the equations of motion for the separation between two particles.  As \"linearized\" suggests, these equations are good to first order in the separation.  Also, the variational equations are associated with a big 6x6 matrix, with the terms of the matrix depending only upon the state of the actual particle.  The terms in the matrix are independent of the state vector describing the separation of the particles.  \n",
    "\n",
    "The variational equations are the result of multiplying this big matrix by the state vector of the current separation.  That means we can multiply the same big matrix by any number of state vectors.   The big matrix is sparse (most of the elements are zero). So, the multiplication is not too expensive.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore this in more detail using the primary routine 'integration_function', which requires more input but allows more control over what is actually integrated.\n",
    "\n",
    "integration_function is called with\n",
    "\n",
    "tstart: the start time in JD (TDB)\n",
    "\n",
    "tend: the end time in JD (TDB)\n",
    "\n",
    "tstep: a suggested time step in days.  The integrator might alter this, depending upon the value of epsilon (see below).\n",
    "\n",
    "geocentric: this is an integer (0 or 1).  0 is for barycentric and 1 is for geocentric.\n",
    "n_particles: the integer number of input particles\n",
    "\n",
    "instates: an array of 6-vectors, each of which is the position and velocity of a test particle at tstart.\n",
    "\n",
    "invar_part: an array of integers that specify which real particle is the host for each input variational particle\n",
    "\n",
    "invar: an array of 6-vectors, each of which represents a variational particle.\n",
    "\n",
    "epsilon: this is a float that affects the adaptive step size control.  The default value is 1e-8.  Negative values indicate a fixed step size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the variational equation by looking at a set of addition real particles.  In particular, we include another six real particles, each offset by a small amount, given by 'scale', along each of those same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "# (3666) Holman\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.338875350265349E+00 Y =-9.176518267602161E-01 Z =-5.038590677470149E-01\n",
    "# VX= 2.805663315227095E-03 VY= 7.550408688437705E-03 VZ= 2.980028207454247E-03\n",
    "    \n",
    "#row =[3.338875350265349E+00, -9.176518267602161E-01, -5.038590677470149E-01, 2.805663315227095E-03, 7.550408688437705E-03, 2.980028207454247E-03]\n",
    "row = [3.338875349745594E+00, -9.176518281675284E-01, -5.038590682977396E-01, 2.805663319000732E-03, 7.550408687780768E-03, 2.980028206579994E-03]\n",
    "\n",
    "tstart, tstep, trange = 2458849.5, 20.0, 10000\n",
    "\n",
    "epoch = tstart\n",
    "tend = tstart + trange\n",
    "\n",
    "instates = np.array([row])\n",
    "n_var = 6\n",
    "n_particles = 7\n",
    "geocentric = 0\n",
    "\n",
    "\n",
    "invar_part = np.zeros(6, dtype=int)\n",
    "invar = np.identity(6)\n",
    "\n",
    "scale = 1e-8\n",
    "instatesp = np.array([row]*6)+scale*invar\n",
    "instates=np.vstack([instates, instatesp])\n",
    "\n",
    "nsubsteps = 10\n",
    "hg = np.arange(0, 1.1, 0.1, dtype=np.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times, states, var, var_ng, status = ephem_forces.integration_function(tstart, tend, tstep, geocentric, \n",
    "                                                                       n_particles, instates, n_var, invar_part, invar, hg,\n",
    "                                                                       nsubsteps=nsubsteps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the difference the x-components of two initially nearby trajectories, as well as the x-component of a corresponding 'variational particle' with the same displacement.  The two curves are offset by a small amount.  Otherwise the difference is not visible on this scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times-times[0], (states[:,1,:]-states[:,0,:])[:,0], label='diff')\n",
    "plt.plot(times-times[0], var[:,0,0]*scale+1e-7, label='vari')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference between the two approaches more clearly by subtracting one from the other.  They are, indeed, very close.  The difference is due to the nonlinear terms that are not included in the variational equations.   The amplitude of difference is quadratic in time.  This is expect as the variational equations are valid to first order in the initial displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times-times[0], (states[:,1,:]-states[:,0,:]-var[:,0,:]*scale)[:,0], label='x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the results for the x, y, and z components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times-times[0], (states[:,1,:]-states[:,0,:]-var[:,0,:]*scale)[:,0], label='x')\n",
    "plt.plot(times-times[0], (states[:,2,:]-states[:,0,:]-var[:,1,:]*scale)[:,1], label='y')\n",
    "plt.plot(times-times[0], (states[:,3,:]-states[:,0,:]-var[:,2,:]*scale)[:,2], label='z')\n",
    "#plt.ylim(-1e-13, 1e-13)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"AU\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebyshev polynomials\n",
    "\n",
    "Each combination of initial conditions and associated parameters represents a trajectory over some time span, finite or infinite.  For the purposes of fitting an orbit to observations, it is necessary to determine the position, and possibly velocity, at the light-time corrected times of the observations.  Thus, it is often necessary to be able to determine the dynamical state at arbitrary times along the trajectory.  Rather than repeated integrating to a set of observation times, it can be more efficient to integrate once to a series of reference times and then interpolate the results for other times.\n",
    "\n",
    "Note that for each overall step taken by the integrator, a number of substeps are included in the output.  I have explored a couple of options for this.  One is output at each of the Gauss-Radau integration substeps.  Another is output at the conventional Chebyshev nodes, as well as the end points.  Both sets of output make interpolation relatively easy, but the latter appears to have better performance.  The goal is to ensure that the error associated with the interpolation is smaller than the error of the integration itself, which is machine precision for IAS15.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instates = np.array([row])\n",
    "n_particles = 1\n",
    "\n",
    "tstart, tstep, trange = 2458849.5, 20.0, 10000\n",
    "\n",
    "epoch = tstart\n",
    "tend = tstart + trange\n",
    "\n",
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.polynomial.chebyshev as ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's set aside for now the idea of using the inverse vandermonde matrix and just concentrate on least squares fitting of chebyshev polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.polynomial.chebyshev.chebpts1(7)\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ch.chebvander(pts, 6 )\n",
    "\n",
    "Vinv = np.linalg.inv(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = statesp[1:8,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.dot(Vinv, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 1, 0.001)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = ch.chebval(x, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y0[0]-y[0])\n",
    "#plt.ylim(-1e-15, 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* integrate the trajectory over a time span. DONE\n",
    "* get the observatory positions for a series of observations (these should be barycentric J2000 equatorial).\n",
    "* fit the segments and save the results. DONE\n",
    "* evaluate the trajectory at various times. DONE\n",
    "* do light-time correction iteration from a specific observatory location at a specific time. DONE\n",
    "* compare the model results to the observed results. DONE\n",
    "* get the partial derivatives of the observables with respect to the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-7*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include geocentric option\n",
    "def get_observation_data(line, geocentric=False):\n",
    "    \n",
    "    fields = line.split()\n",
    "    trackletID = fields[0].strip()\n",
    "    obsCode = fields[4].strip()\n",
    "    jd_tdb = float(fields[7])\n",
    "        \n",
    "    x_target, y_target, z_target = fields[8:11]\n",
    "    r_target = np.array([float(x_target), float(y_target), float(z_target)])\n",
    "\n",
    "    x_obs, y_obs, z_obs = fields[11:14]\n",
    "    r_obs = np.array([float(x_obs), float(y_obs), float(z_obs)])\n",
    "    if geocentric:\n",
    "        r_E = np.array(MPC_library.getEarthPosition(jd_tdb))\n",
    "        #r_E = np.array(ephem_forces.all_ephem(3, jd_tdb)[1:4])\n",
    "        r_obs -= r_E\n",
    "        print(jd_tdb, r_obs, obsCode)\n",
    "    \n",
    "    return jd_tdb, r_target, r_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis(v):\n",
    "    x, y, z = v\n",
    "    r = np.sqrt(x*x + y*y)\n",
    "    if r==0.0:\n",
    "        A = np.array((-1, 0.0, 0.0))\n",
    "    else:\n",
    "        A = np.array((-y/r, x/r, 0.0))\n",
    "    \n",
    "    D = np.cross(v, A)\n",
    "    \n",
    "    return A, D\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array((0, 1, 0))\n",
    "A, D = get_basis(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(36*8 + 36)/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(v1, v2):\n",
    "    # This can be streamlined\n",
    "    # The A and D matrices and be\n",
    "    # saved for each data point\n",
    "    x, y, z = v1\n",
    "    #r = np.sqrt(x*x + y*y)\n",
    "    delta = np.arcsin(z)\n",
    "    alpha = np.arctan2(y, x)\n",
    "    sina = np.sin(alpha)\n",
    "    #sina = y/r\n",
    "    cosa = np.cos(alpha)\n",
    "    #cosa = x/r\n",
    "    sind = np.sin(delta)\n",
    "    #sind = z\n",
    "    cosd = np.cos(delta)\n",
    "    A = np.array((-sina, cosa, 0.0))\n",
    "    D = np.array((-sind*cosa, -sind*sina, cosd))\n",
    "    return (np.dot(v2, A), np.dot(v2, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trajectory(times, states):\n",
    "    fits = []\n",
    "    time_tags = []\n",
    "    for i in range(0, len(times)-1, 8):\n",
    "        data = np.reshape(states[i:i+9,:,0:3], (9, 3))\n",
    "        x = times[i:i+9]-times[i+4]\n",
    "        t0 = times[i+4]\n",
    "        dt = x[-1]-x[0]\n",
    "        f = ch.chebfit(2*x/dt, data, 7)\n",
    "        fits.append((t0, dt, f))\n",
    "        time_tags.append(times[i])\n",
    "    time_tags = np.array(time_tags)\n",
    "    return time_tags, fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "# (3666) Holman\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.338875349745594E+00 Y =-9.176518281675284E-01 Z =-5.038590682977396E-01\n",
    "# VX= 2.805663319000732E-03 VY= 7.550408687780768E-03 VZ= 2.980028206579994E-03\n",
    "row = [3.338875349745594E+00, -9.176518281675284E-01, -5.038590682977396E-01, 2.805663319000732E-03, 7.550408687780768E-03, 2.980028206579994E-03]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = 2458895.017041\n",
    "\n",
    "       \n",
    "#       2458895.017041000 = A.D. 2020-Feb-15 12:24:32.3424 TDB [del_T=     69.185127 s]\n",
    "# X =-8.249088716487324E-01 Y = 5.128233312454121E-01 Z = 2.229322025922279E-01\n",
    "# VX=-1.055227553661174E-02 VY=-1.358415461735038E-02 VZ=-5.295679016887025E-03\n",
    "row = [-8.249088716487324E-01, 5.128233312454121E-01, 2.229322025922279E-01,\n",
    "        -1.055227553661174E-02, -1.358415461735038E-02, -5.295679016887025E-03]\n",
    "\n",
    "#2458894.500000000 = A.D. 2020-Feb-15 00:00:00.0000 TDB [del_T=     69.185116 s]\n",
    "# X =-8.193874027610940E-01 Y = 5.198340919082048E-01 Z = 2.256562195597833E-01\n",
    "# VX=-1.081684176011098E-02 VY=-1.353532640193796E-02 VZ=-5.241845834560792E-03\n",
    "\n",
    "#2458894.500000000 = A.D. 2020-Feb-15 00:00:00.0000 TDB [del_T=     69.185116 s]\n",
    "row = [-8.193874027610940E-01, 5.198340919082048E-01, 2.256562195597833E-01,\n",
    "       -1.081684176011098E-02, -1.353532640193796E-02, -5.241845834560792E-03]\n",
    "\n",
    "#2458897.500000000 = A.D. 2020-Feb-18 00:00:00.0000 TDB [del_T=     69.185180 s]\n",
    "# X =-8.499386338554212E-01 Y = 4.787625651895777E-01 Z = 2.094777670024411E-01\n",
    "# VX=-9.661210198068209E-03 VY=-1.385885178755969E-02 VZ=-5.532765642013616E-03\n",
    "row = [-8.499386338554212E-01, 4.787625651895777E-01, 2.094777670024411E-01, \n",
    "    -9.661210198068209E-03, -1.385885178755969E-02, -5.532765642013616E-03]\n",
    "\n",
    "#2458897.500000000 = A.D. 2020-Feb-18 00:00:00.0000 TDB [del_T=     69.185180 s]\n",
    "# X =-3.118500479970055E-03 Y =-1.512873873465409E-03 Z = 1.239844826099388E-03\n",
    "# VX=-3.789003661569063E-04 VY=-3.369885641555601E-04 VZ= 3.279972338540866E-04\n",
    "row = [-3.118500479970055E-03, -1.512873873465409E-03, 1.239844826099388E-03, \n",
    "     -3.789003661569063E-04, -3.369885641555601E-04, 3.279972338540866E-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instates = np.array([row])\n",
    "\n",
    "n_particles = 1\n",
    "\n",
    "tstart, tstep, trange = 2458849.5, 2.0, 2000\n",
    "tstart, tstep, tend = 2458894.500000000, 2, 2458932.50\n",
    "\n",
    "epoch = 2458897.500000000\n",
    "#tend = tstart + trange\n",
    "\n",
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates, tstep=2.0, geocentric=1)#, epsilon=1e-8, tstep=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timesp), len(statesp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp[-1], statesp[-1], statesp[0], timesp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2458894.500000000 = A.D. 2020-Feb-15 00:00:00.0000 TDB [del_T=     69.185116 s]\n",
    "K20C03D = np.array([-1.562333877039780E-03, -3.277988442969260E-04, 1.300908692605723E-04,\n",
    "     -7.738749028274221E-04, -4.723132211708606E-04, 4.202738544505411E-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " K20C03D = np.array([-8.855745866541963E-03, -6.174222186235641E-03, 7.065718386911509E-03,\n",
    " -1.282144988613095E-04, -1.338814161041129E-05, 6.548842150422916E-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(K20C03D - statesp[-1])*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(row).reshape(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6400*2*3.14/(24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "with open('3666_eq_bary.mpc') as file:\n",
    "        line=file.readline()\n",
    "        for line in file:\n",
    "            jd_tdb, r_target, r_obs = get_observation_data(line)\n",
    "            obs.append((jd_tdb, r_target, r_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2458895.017041000 = A.D. 2020-Feb-15 12:24:32.3424 TDB [del_T=     69.185127 s]\n",
    " X =-8.229843715810257E-01 Y = 5.133866216380784E-01 Z = 2.225894275786583E-01\n",
    " VX=-9.913923474824957E-03 VY=-1.314467346840790E-02 VZ=-5.697451462034082E-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-8.229843715810257E-01 - -0.82298367)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2458895.017040800 = A.D. 2020-Feb-15 12:24:32.3251 TDB [del_T=     69.185129 s]\n",
    " X = 2.764507164403535E-05 Y = 2.305643106867868E-05 Z =-2.280392275599578E-05\n",
    " VX=-1.452631451039335E-04 VY= 1.744508044393150E-04 VZ= 2.807803667368201E-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2458895.017041000 = A.D. 2020-Feb-15 12:24:32.3424 TDB [del_T=     69.185129 s]\n",
    " X = 2.764504255720905E-05 Y = 2.305646599986323E-05 Z =-2.280392269977366E-05\n",
    " VX=-1.452633651835234E-04 VY= 1.744506211807041E-04 VZ= 2.807807889159410E-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.764507164403535E-05 - 2.76444902e-05)*1.5e8, (2.305646599986323E-05-2.30537690e-05)*1.5e8, (-2.280392269977366E-05- -2.28050798e-05)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.4*1.4/384400 )*206265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2458895.496318000 = A.D. 2020-Feb-15 23:54:41.8752 TDB [del_T=     69.185137 s]\n",
    " X = 2.766814748701722E-05 Y =-1.157852792138350E-05 Z =-3.020367669904454E-05\n",
    " VX= 7.295045605972016E-05 VY= 1.746859269841296E-04 VZ=-1.391190084195478E-07    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-2.76658342e-05 - -2.766814748701722E-05)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "with open('K20C03D_eq_bary.mpc') as file:\n",
    "        line=file.readline()\n",
    "        for line in file:\n",
    "            jd_tdb, r_target, r_obs = get_observation_data(line, geocentric=True)\n",
    "            obs.append((jd_tdb, r_target, r_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segment(time_tags, t, tmax):\n",
    "    if t < time_tags[0] or t > tmax:\n",
    "        return -1\n",
    "    elif t==time_tags[0]:\n",
    "        return 0\n",
    "    else:\n",
    "        idx = np.searchsorted(time_tags, t)\n",
    "        return idx-1\n",
    "\n",
    "\n",
    "\n",
    "def trajectory(fits, time_tags, t, tmax):\n",
    "    idx = find_segment(time_tags, t, tmax)\n",
    "    t0, dt, c = fits[idx]\n",
    "    x = 2*(t - t0)/dt\n",
    "    model = ch.chebval(x, c)\n",
    "    return model\n",
    "\n",
    "au_km = 149597870.700 # This is now a definition \n",
    "speed_of_light = 2.99792458e5 * 86400./au_km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to include a geocentric option\n",
    "def generate_observation(fits, time_tags, r_obs, t_obs, niter=5):\n",
    "    lt = 0.0\n",
    "    # probably don't need to look up the segment every time\n",
    "    # probably don't need very high order chebyshev polynomials\n",
    "    # probably already have a guess at lt from previous iterations.\n",
    "    for i in range(niter):\n",
    "        t = t_obs - lt\n",
    "        pos = trajectory(fits, time_tags, t, timesp[-1])\n",
    "        rho = pos-r_obs\n",
    "        delta = np.sqrt(rho[0]*rho[0] + rho[1]*rho[1] + rho[2]*rho[2])\n",
    "        #delta = np.linalg.norm(rho)\n",
    "        rho = rho/delta\n",
    "        lt = delta/speed_of_light\n",
    "    return rho, lt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(instates, obs, tstart, tend, geocentric=True):\n",
    "    instates = instates.reshape(1, 6)\n",
    "    timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates, tstep=2.0, geocentric=geocentric)\n",
    "    time_tags, fits = save_trajectory(timesp, statesp)\n",
    "    resid = []\n",
    "    # don't need to repeatedly open this file to read and format the data\n",
    "    for jd_tdb, r_target, r_obs in obs:\n",
    "        model, lt = generate_observation(fits, time_tags, r_obs, jd_tdb)\n",
    "        dx, dy = get_residuals(r_target, model)\n",
    "        resid.append(dx)\n",
    "        resid.append(dy)\n",
    "        print(\"%.6lf %.5lf %7.3lf %7.3lf\" % (jd_tdb, lt, dx*206265, dy*206265))\n",
    "    return resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "results = least_squares(residuals, np.array(row), args=(obs, tstart, tend), xtol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results.x - instates[0])*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res0 = np.array(residuals(np.array(row).reshape(1, 6), obs, tstart, tend, geocentric=True))*206265\n",
    "res1 = np.array(residuals(results.x, obs, tstart, tend))*206265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0.mean(), res0.std(), res1.mean(), res1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instates_res = np.array([results.x.tolist()])\n",
    "\n",
    "n_particles = 1\n",
    "\n",
    "tstart, tstep, tend = 2458694.500000000, 2, 2459232.50\n",
    "\n",
    "epoch = 2458897.500000000\n",
    "\n",
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates_res, tstep=2.0, geocentric=1)#, epsilon=1e-8, tstep=20)\n",
    "\n",
    "tstart, tstep, tend = 2458894.500000000, 2, 2458932.50\n",
    "timesf, statesf, varf, varf_ng, statusf = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates_res, tstep=2.0, geocentric=1)#, epsilon=1e-8, tstep=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,5))\n",
    "#plt.figure(figsize=(5, 5))\n",
    "ax.plot(statesp[:,:,0], statesp[:,:,1])\n",
    "ax.plot(statesf[:,:,0], statesf[:,:,1])\n",
    "ax.set_xlim(-0.030, 0.005)\n",
    "ax.set_ylim(-0.020, 0.010)\n",
    "ax.set_xlabel('x (AU)')\n",
    "ax.set_ylabel('y (AU)')\n",
    "plt.savefig('2020_CD3.png')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first(x):\n",
    "    return x[0]\n",
    "\n",
    "def second(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3400*1.0625/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5*384400/1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.array(list(map(first, obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,5))\n",
    "\n",
    "\n",
    "ax.scatter(ts-ts[0], res1[0::2], s=4)\n",
    "ax.scatter(ts-ts[0], res1[1::2], s=4)\n",
    "ax.set_xlabel('days')\n",
    "ax.set_ylabel('residual (arcsec)')\n",
    "plt.savefig('residuals.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, obs[0], tend, obs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_= plt.hist(res0, bins=30)\n",
    "_= plt.hist(res1, bins=30)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x - np.array(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instates = np.array([row])\n",
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, instates)\n",
    "\n",
    "time_tags, fits = save_trajectory(timesp, statesp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diffs = []\n",
    "for i, t in enumerate(timesp):\n",
    "    diffs.append(statesp[i][0][0:3]-trajectory(fits, time_tags, t, timesp[-1]))\n",
    "\n",
    "diffs = np.array(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = trajectory(fits, time_tags, 2467000.5, timesp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " test = np.array([3.513219995999942E+00, -6.229832838087752E-02, -1.608033362738477E-01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test - trajectory(fits, time_tags, 2467000.5, timesp[-1]))*1.5e11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolation errors look to be substantially less than 1 m, which is certainly good.  But I'm not quite sure why it's so large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(timesp-timesp[0], diffs[:,0]*1.5e11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step will be to iteratively generate a light-time corrected RA/Dec observation from a particular observatory at a particular observing time.\n",
    "\n",
    "F51 at JD 2467000.5 TDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F51 = np.array([-8.162323545253964E-01, -5.297985179472369E-01, -2.298084817347363E-01])\n",
    "F51 = np.array([-9.116190007936418E-01, 3.719152151402167E-01, 1.614743792421127E-01])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = 2460000.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_observation(fits, time_tags, F51, t_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = (pos-F51)/delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((180./np.pi*np.arctan2(y, x)) + 360 - 204.262489518)*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(180./np.pi*np.arcsin(z) - -6.836971568)*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "00 24 38.49 +00 54 24.4\n",
    "13 37 03.00 -06 50 13.1\n",
    "204.262489518  -6.836971568\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = 69.185544/86400.\n",
    "delta_t = 69.185284/86400.\n",
    "t_utc = t_obs-delta_t\n",
    "t_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "sat_dict = defaultdict(list)\n",
    "with open('3le_new.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    first = lines[0::3]\n",
    "    second = lines[1::3]\n",
    "    third = lines[2::3]\n",
    "    names = list(map(lambda x: x[2:].rstrip(), first))\n",
    "    mm = list(map(lambda x: float(x[53:64]), third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(mm, bins=21, cumulative=False, range=(0,1.05))\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.xlabel('rev/day')\n",
    "plt.ylabel('N')\n",
    "plt.savefig('rev_hist_v4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_dict = {k:v for k,v in zip(names, mm)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secnd(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names_mm.txt', 'w') as f:\n",
    "    for k,v in sorted(zip(names, mm), key=secnd):\n",
    "        f.write('%15f %s\\n'% (v, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenging Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try some more challenging cases.  First Apophis, an NEO that makes repeated close approaches to Earth.  It will make an approach on 2021 Mar 06 1:06 UT.  This approach will not be particularly close.  However, the 2029 Apr 13 approach will be extremely close.\n",
    "\n",
    "The initial conditions below are for 2020 Aug 01, before the first approach.  We will integrate through the first approach and to just before the closer second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ephem_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "#2459062.500000000 = A.D. 2020-Aug-01 00:00:00.0000 TDB [del_T=     69.183254 s]\n",
    "# X =-5.147481787179418E-03 Y =-7.554300268214853E-01 Z =-2.803431979691921E-01\n",
    "# VX= 1.994372371206607E-02 VY= 2.695051098855493E-03 VZ= 1.506829667479476E-03\n",
    "row = [-5.147481787179418E-03, -7.554300268214853E-01, -2.803431979691921E-01,\n",
    "        1.994372371206607E-02, 2.695051098855493E-03, 1.506829667479476E-03]\n",
    "\n",
    "# DE431\n",
    "#row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "    \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3150\n",
    "tend = tstart + trange\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "instates = np.array(row)\n",
    "\n",
    "times, states, var, var_ng, status = ephem_forces.integration_function(tstart, tend, tstep, geocentric, \n",
    "                                                               n_particles, instates, n_var, invar_part, invar)#, epsilon=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1], states[-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2462212.500000000 = A.D. 2029-Mar-17 00:00:00.0000 TDB [del_T=     69.185579 s]\n",
    " X =-1.065242948790426E+00 Y = 1.336576685926274E-02 Z =-2.189407072944644E-02\n",
    " VX= 1.615083976122256E-03 VY=-1.426641205899967E-02 VZ=-5.259456864467629E-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No non-gravs\n",
    "apophis_before = np.array([\n",
    "-1.065242948790426E+00, 1.336576685926274E-02, -2.189407072944644E-02,\n",
    " 1.615083976122256E-03, -1.426641205899967E-02, -5.259456864467629E-03])\n",
    "\n",
    "\n",
    "# Including non-gravs\n",
    "# dt_min = 1e-3\n",
    "# epsilon = 1e-8\n",
    "#apophis_before = np.array([\n",
    "#    -1.061749621090919E+00, -1.342851936299780E-02, -3.176051171408323E-02,\n",
    "#     2.104893542927364E-03, -1.426673477234808E-02, -5.247194855985309E-03])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states[-1][0]-apophis_before)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest discrepancy is ~42 km just before the 2029 close approach.\n",
    "\n",
    "Now I will include the non-gravitational terms, using the A2 value provided by JPL Horizons (A1 and A3 = 0.0).\n",
    "\n",
    "At the moment, the non-grav values are hard-coded.  The code needs to be recompiled and the library reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ephem_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "#2459062.500000000 = A.D. 2020-Aug-01 00:00:00.0000 TDB [del_T=     69.183254 s]\n",
    "# X =-5.147481787179418E-03 Y =-7.554300268214853E-01 Z =-2.803431979691921E-01\n",
    "# VX= 1.994372371206607E-02 VY= 2.695051098855493E-03 VZ= 1.506829667479476E-03\n",
    "row = [-5.147481787179418E-03, -7.554300268214853E-01, -2.803431979691921E-01,\n",
    "        1.994372371206607E-02, 2.695051098855493E-03, 1.506829667479476E-03]\n",
    "\n",
    "# DE431\n",
    "#row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "    \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3150\n",
    "tend = tstart + trange\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "instates = np.array(row)\n",
    "\n",
    "times, states, var, var_ng, status = ephem_forces.integration_function(tstart, tend, tstep, geocentric, n_particles, instates, n_var, invar_part, invar)#, epsilon=1e-8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_after = np.array([\n",
    "-6.343441804789555E-01, -6.456269834869176E-01, -2.636333964165063E-01,\n",
    " 1.546139923046551E-02, -1.029411916646655E-02, -3.777044399870865E-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0], (states[-1][0]-apophis_before)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0], (states[-1][0]-apophis_after)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the largest discrepancy is ~1 km.  How carefully the very close approaches are handled matters, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try geocentric integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [6.634500992578179E-02, 2.122458699845356E-03, -3.507415858744104E-04,\n",
    "     -1.060257698567525E-03, 6.078332955992950E-04, 2.240712392485767E-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2459062.5, -1.0, -400\n",
    "geocentric = 1\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "instates = np.array(row)\n",
    "timesb, statesb, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesb[:,0,0], statesb[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2459062.5, 1.0, 400\n",
    "geocentric = 1\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "instates = np.array(row)\n",
    "\n",
    "timesf, statesf, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesf[:,0,0], statesf[:,0,1])\n",
    "plt.plot(statesb[:,0,0], statesb[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = timesb[-1], 1.0, 400\n",
    "instatesb = statesb[-1][0].copy()\n",
    "timesf, statesf, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instatesb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesb[:,0,0], statesb[:,0,1])\n",
    "\n",
    "plt.plot(statesf[:,0,0], statesf[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2462263.697021989 = A.D. 2029-May-07 04:43:42.6999 TDB \n",
    " X = 7.771821449378258E-02 Y = 1.444568330466675E-02 Z = 2.318152988506329E-02\n",
    " VX= 3.531021355764523E-03 VY= 8.992784904633009E-04 VZ= 1.064745760510192E-03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_geo_after=np.array([\n",
    "    7.771821449378258E-02, 1.444568330466675E-02, 2.318152988506329E-02, \n",
    "    3.531021355764523E-03, 8.992784904633009E-04, 1.064745760510192E-03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states[-1][0]-apophis_geo_after)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worse.  I wonder if this is due to the interpolated acceleration of the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    t, p0, p1, p2 = results\n",
    "    d = np.linalg.norm(p0, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='x')\n",
    "    #plt.plot(t, d, label='x')\n",
    "    d = np.linalg.norm(p1, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='y')\n",
    "    #plt.plot(t, d, label='y')\n",
    "    d = np.linalg.norm(p2, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='z')\n",
    "    #plt.plot(t, d, label='z')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_x = np.array(sorted([(k, np.linalg.norm(p0[-1]), np.linalg.norm(p1[-1]), np.linalg.norm(p2[-1])) for k, (t, p0, p1, p2) in results_dict.items()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prec_x[:,0], prec_x[:, 1])\n",
    "plt.plot(prec_x[:,0], prec_x[:, 2])\n",
    "plt.plot(prec_x[:,0], prec_x[:, 3])\n",
    "plt.yscale('log')\n",
    "plt.xscale ('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_dict[1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-8, -2, num=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
